############################### CNN Ä°LE BEYÄ°N TUMOR TESPÄ°TÄ° ###############################
"""
!pip install split-folders
!pip install torch-summary

split-folders â†’ Veriyi eÄŸitim/test/doÄŸrulama kÃ¼melerine bÃ¶lmek iÃ§in
torch-summary â†’ PyTorch modellerinin detaylarÄ±nÄ± Ã¶zetlemek iÃ§in, katmanlar ve parametrelerin kullanmÄ± iÃ§in
"""
#bu iki kÃ¼tÃ¼phaneyi yÃ¼kledik

# Gerekli kÃ¼tÃ¼phaneleri iÃ§e aktarÄ±n
import pandas as pd  # Veri iÅŸleme ve analiz iÃ§in kullanÄ±lan kÃ¼tÃ¼phane
import seaborn as sns
sns.set(style='darkgrid')  # GeliÅŸmiÅŸ veri gÃ¶rselleÅŸtirme kÃ¼tÃ¼phanesi (karanlÄ±k Ä±zgara temasÄ±yla)
import pathlib  # Dosya ve dizin yollarÄ±yla Ã§alÄ±ÅŸmak iÃ§in kullanÄ±lan kÃ¼tÃ¼phane
import os
import matplotlib.pyplot as plt
from PIL import Image

####################### VERÄ° YUKLEME ###################################

labels_df = pd.read_csv("!!!!...Enter csv file path...!!!!!")   #pip install tabulate  kÃ¼tÃ¼phanesini indirdik
print("----------------------- VERÄ° SETÄ° -----------------------")
print(labels_df.head().to_markdown())  #verinin Ã¶zelliklerini tablo ÅŸekilnde getirir.
print(f"\nSatÄ±r ve SÃ¼tun SayÄ±sÄ±: {labels_df.shape}") #kaÃ§ satÄ±r ve kaÃ§ sÃ¼tun adÄ±ndan oluÅŸtuÄŸunu getirir

##################### veri setini ayÄ±rmamÄ±z gerekiyor ama ben ilk Ã¶nce hem veri setini arttÄ±rmak hem de Ã§eÅŸitlilik saÄŸlamak iÃ§in her gÃ¶rÃ¼ntÃ¼nÃ¼n horizontal ve 10 derece dÃ¶ndÃ¼rÃ¼lmÃ¼ÅŸ halini de ekleyeceÄŸim



# Veri seti klasÃ¶rleri
input_folder = "!!!!...Enter input dataset path...!!!!!"
output_folder = "!!!!...Enter new output dataset path...!!!!!"

# SaÄŸlÄ±klÄ± ve tÃ¼mÃ¶rlÃ¼ klasÃ¶rlerini al
categories = ["Brain Tumor", "Healthy"]

# GÃ¶rselleri dÃ¶ndÃ¼rme fonksiyonu
def transform_rotate(image):
    angle = 10  # 10 derece dÃ¶ndÃ¼rme
    return image.rotate(angle)

# Veri artÄ±rma iÅŸlemi
for category in categories:
    category_path = os.path.join(input_folder, category)  # Kategoriye Ã¶zel yol
    save_path = os.path.join(output_folder, category)  # Yeni resimleri kaydetme klasÃ¶rÃ¼

    # Kategorinin Ã§Ä±ktÄ±sÄ±nÄ± oluÅŸtur
    os.makedirs(save_path, exist_ok=True) #yoldaki klasÃ¶rleri oluÅŸturur dosyalar zaten varsa hata vermez.

    for img_name in os.listdir(category_path):  #brain tumor, healty deki tÃ¼m resimleri gezeceÄŸiz.
        img_path = os.path.join(category_path, img_name)

        # GÃ¶rseli aÃ§
        img = Image.open(img_path)

        # Orijinal gÃ¶rseli de kaydet

        img = img.convert('RGB')  # farklÄ± tÃ¼rdeki resimleri RGB'ye dÃ¶nÃ¼ÅŸtÃ¼r
        img.save(os.path.join(save_path, f"original_{img_name}"))

        # GÃ¶rseli yatay olarak dÃ¶ndÃ¼rme (flip)
        flipped_img = img.transpose(Image.FLIP_LEFT_RIGHT)

        # DÃ¶ndÃ¼rÃ¼len gÃ¶rseli kaydetme
        flipped_img.save(os.path.join(save_path, f"flip_{img_name}"))

        # GÃ¶rseli dÃ¶ndÃ¼rme (10 derece)
        rotated_img = transform_rotate(img)

        # DÃ¶ndÃ¼rÃ¼len gÃ¶rseli kaydetme
        rotated_img.save(os.path.join(save_path, f"rotate_{img_name}"))

print("Veri artÄ±rma tamamlandÄ±! Yeni resimler kaydedildi.")

# DataFrame iÃ§in boÅŸ listeler
metadata = []
metadata_rgb = []

# GÃ¶rsellerin bilgilerini toplama
for category in categories:
    category_path = os.path.join(output_folder, category)  # Kategoriye Ã¶zel yol

    for img_name in os.listdir(category_path):
        img_path = os.path.join(category_path, img_name)

        # GÃ¶rseli aÃ§
        img = Image.open(img_path)

        # GÃ¶rselin formatÄ±, modu ve ÅŸekli
        img_format = img.format
        img_mode = img.mode
        img_shape = img.size + (len(img.getbands()),)  # width, height, num_channels

        # Resmin bilgilerini dataframe iÃ§in hazÄ±rlama
        row = {
            'image': img_name,  # --> ismi
            'class': category,   #--> tumor, healthy
            'format': img_format, #--> dosya uzantÄ±sÄ±
            'mode': img_mode, #--> RGB falan
            'shape': img_shape # -->boyut
        }

        # TÃ¼m gÃ¶rsellerin metadata'sÄ±nÄ± ekleme
        metadata.append(row)

        # Sadece RGB olanlarÄ± ayÄ±rma
        if img_mode == 'RGB':
            metadata_rgb.append(row)

# DataFrame oluÅŸturma
metadata_df = pd.DataFrame(metadata)
metadata_rgb_df = pd.DataFrame(metadata_rgb)

# Excel dosyasÄ±nÄ± kaydetme
metadata_file = "...new output folder path.../metadata.xlsx"
metadataonlyrgb_file = "...new output folder path.../metadataonlyrgb.xlsx"

# Excel dosyasÄ±na yazma
metadata_df.to_excel(metadata_file, index=False)  #false olduÄŸu iÃ§in satÄ±r numaralarÄ±nÄ± excele yazmaz.
metadata_rgb_df.to_excel(metadataonlyrgb_file, index=False)

print(f"Metadata dosyalarÄ± oluÅŸturuldu: \n{metadata_file} \n{metadataonlyrgb_file}")

############################################################################ veri setindeki tÃ¼m resimleri yatayda ve 10 derece dÃ¶ndÃ¼rerek saÄŸlÄ±klÄ± ve tÃ¼morlÃ¼ veri sayÄ±sÄ±nÄ± *2 kat arttÄ±rdÄ±m.
#10 derece dÃ¶ndÃ¼rmemin sebebi bunlar saÄŸlÄ±k verisi olduÄŸu iÃ§in hem Ã§eÅŸitlendirmeyi saÄŸlamak hem de Ã§ok fazla dÃ¶ndÃ¼rmediÄŸim iÃ§in gÃ¶rselin ana yapÄ±sÄ±nÄ± da bozup Ã¶ÄŸrenmeyi zorlaÅŸtÄ±rmamak
#excele de yeni verileri yazdÄ±rdÄ±m.
## veri setini Ã§evirdikten sonra tekrardan gÃ¼ncel verilerimizi okuyalÄ±m


####################### YENÄ° VERÄ° YUKLEME ###################################

labels_df = pd.read_excel("...new output folder path.../metadata.xlsx")
print("\n----------------------- YENÄ° VERÄ° SETÄ° -----------------------")
print(labels_df.head().to_markdown())
print(f"\nSatÄ±r ve SÃ¼tun SayÄ±sÄ±: {labels_df.shape}") #kaÃ§ satÄ±r ve kaÃ§ sÃ¼tun adÄ±ndan oluÅŸtuÄŸunu getirir.

tumor_path = "...new output folder path.../Brain Tumor"
healthy_path = "...new output folder path.../Healthy"

# KlasÃ¶rdeki dosya sayÄ±sÄ±nÄ± hesapla
num_tumor = len(os.listdir(tumor_path))
num_healthy = len(os.listdir(healthy_path))

# Verileri hazÄ±rla
categories = ["Tumor", "Healthy"]
counts = [num_tumor, num_healthy]


plt.figure(figsize=(6,5)) #Histogram iÃ§in ekran boyutu
plt.bar(categories, counts, color=['blue', 'purple']) #kategori renkleri
plt.xlabel("SÄ±nÄ±f")# X eksenine etiket ekle
plt.ylabel("Veri SayÄ±sÄ±")# Y eksenine etiket ekle
plt.title("TÃ¼mÃ¶rlÃ¼ ve SaÄŸlÄ±klÄ± Beyin MR GÃ¶rÃ¼ntÃ¼sÃ¼ Veri DaÄŸÄ±lÄ±mÄ±")

# Y eksenine grid Ã§izgileri ekle, sadece yatay eksende ve Ã§izgilerin stilini belirle
plt.grid(axis='y', linestyle='--', alpha=0.5, color='black')   #0.5 saydamlÄ±ÄŸÄ± belirler

# Her bir barÄ±n Ã¼stÃ¼ne veri sayÄ±sÄ±nÄ± ekle
for i, count in enumerate(counts):  # 'counts' listesinde her bir veri iÃ§in
    plt.text(i, count + 10, str(count), ha='center', fontsize=12)  # 'count' sayÄ±sÄ±nÄ±, barÄ±n biraz Ã¼stÃ¼ne ekler    x,y,yazÄ±,ortala,font
plt.show()

#####################################################################################################################
#burada veri setimizi stratify olacak ÅŸekilde train test ve validation setlerine bÃ¶lÃ¼yoruz artÄ±k modelimizi bu veriler Ã¼zerinden iÅŸleyeceÄŸiz.
#Veriler orantÄ±lÄ± bir ÅŸekilde geliyor sÄ±kÄ±ntÄ± yok bu kÄ±sÄ±m da sadece eÄŸitim test val. verilerini oluÅŸturmak iÃ§in Ã¶nemliydi artÄ±k kullanmayacaÄŸÄ±z yorum satÄ±rÄ±na alabiliriz.

import pathlib
import splitfolders
import os

# Dataset Path
data_dir = "C:/Users/Ceren/Desktop/beyinVeri-KopyaCevrilmis"
data_dir = pathlib.Path(data_dir)

# Ratio fonksiyonu ile birlikte veri seti dengeli (stratify) bÃ¶lÃ¼nmÃ¼ÅŸtÃ¼r.
splitfolders.ratio(data_dir, output="C:/Users/Ceren/Desktop/beyinVeri-KopyaCevrilmis/brain",
                   seed=42, ratio=(0.7, 0.15, 0.15), group_prefix=None)  #none demeseydik dosya isimlerine gÃ¶re gruplandÄ±rÄ±lacaklardÄ± ÅŸu anda rastgele oluyor.

# Yeni yol
data_dir = pathlib.Path("C:/Users/Ceren/Desktop/beyinVeri-KopyaCevrilmis/brain")

# Veri sayÄ±sÄ± hesaplama --> walk fonksiyonu recursive olduÄŸu iÃ§in dosyalar arasÄ±nda derinlemesine ilerler.
def count_images(directory):
    return sum([len(files) for _, _, files in os.walk(directory)])   #-->	O anda gezilen klasÃ¶rÃ¼n tam yolu,Bu klasÃ¶r iÃ§indeki alt klasÃ¶rlerin isim listesi,Bu klasÃ¶r iÃ§indeki dosya isimlerinin listesi

train_count = count_images(data_dir / "train")
val_count = count_images(data_dir / "val")
test_count = count_images(data_dir / "test")
total_count = train_count + val_count + test_count

# Print counts
print(f"Train Set: {train_count} images")
print(f"Validation Set: {val_count} images")
print(f"Test Set: {test_count} images")
print(f"Total Images: {total_count}")

############################## TRAÄ°N TEST VALÄ°DATÄ°ON VERÄ°LERÄ°MÄ°ZÄ° GÃ–RSELLEÅTÄ°RME ############################
# Dosya yollarÄ±
path = "C:/Bilgisayarim/bilgisayarMuhendisligi/3.sÄ±nÄ±fBaharKod/yapayZeka/beyinVeri-KopyaCevrilmis/brain"
paths = {
    "train": os.path.join(path, "train"),
    "val": os.path.join(path, "val"),
    "test": os.path.join(path, "test")
}

# Dosya sayÄ±sÄ±nÄ± almak iÃ§in fonksiyon
def count_files(path):
    tumor_count = len(os.listdir(os.path.join(path, 'Brain Tumor')))
    healthy_count = len(os.listdir(os.path.join(path, 'Healthy')))
    return tumor_count, healthy_count

# Histogram Ã§izim fonksiyonu
def plot_histogram(categories, counts, title):
    plt.figure(figsize=(6, 5))  # Histogram iÃ§in ekran boyutu
    plt.bar(categories, counts, color=['green', 'orange'])  # Kategori renkleri
    plt.xlabel("SÄ±nÄ±f")  # X eksenine etiket ekle
    plt.ylabel("Veri SayÄ±sÄ±")  # Y eksenine etiket ekle
    plt.title(title)
    plt.grid(axis='y', linestyle='--', alpha=0.5, color='black')
    for i, count in enumerate(counts):
        plt.text(i, count + 10, str(count), ha='center', fontsize=12)  # Veri sayÄ±sÄ±nÄ± barÄ±n Ã¼stÃ¼ne ekle
    plt.show()

# Verileri hazÄ±rla
categories = ["Tumor", "Healthy"]

# Train, Validation ve Test setleri iÃ§in dosya sayÄ±sÄ±nÄ± hesapla
train_counts = count_files(paths["train"])
val_counts = count_files(paths["val"])
test_counts = count_files(paths["test"])

# HistogramlarÄ± Ã§iz
plot_histogram(categories, train_counts, "Train Set: TÃ¼mÃ¶rlÃ¼ ve SaÄŸlÄ±klÄ± Beyin MR GÃ¶rÃ¼ntÃ¼sÃ¼ Veri DaÄŸÄ±lÄ±mÄ±")
plot_histogram(categories, val_counts, "Validation Set: TÃ¼mÃ¶rlÃ¼ ve SaÄŸlÄ±klÄ± Beyin MR GÃ¶rÃ¼ntÃ¼sÃ¼ Veri DaÄŸÄ±lÄ±mÄ±")
plot_histogram(categories, test_counts, "Test Set: TÃ¼mÃ¶rlÃ¼ ve SaÄŸlÄ±klÄ± Beyin MR GÃ¶rÃ¼ntÃ¼sÃ¼ Veri DaÄŸÄ±lÄ±mÄ±")



#################### VERÄ° Ã‡EÅÄ°TLENDÄ°RME UYGULAYACAÄIZ (ilk baÅŸta biz veriyi Ã§evirmiÅŸtik ama burada resimlerin de aynÄ± boyutta olmalarÄ±nÄ± saÄŸlayacaÄŸÄ±z  ###################

import torch  #Tensor iÅŸlemleri, model oluÅŸturma
import torchvision  #PyTorcha baÄŸlÄ± gÃ¶rÃ¼ntÃ¼ iÅŸleme kÃ¼tÃ¼phanesi
from torchvision import datasets,transforms  #GÃ¶rÃ¼ntÃ¼lerin modele girmeden Ã¶nce dÃ¶nÃ¼ÅŸtÃ¼rlmesini saÄŸlar.
import numpy as np   #tensorleri numpy arraylerine Ã§evirir.

# Veri seti ve transform ayarlarÄ±nÄ± tanÄ±mlÄ±yoruz
data_dir = pathlib.Path(path)

# GÃ¶rselleri yÃ¼kleyerek her bir kanal iÃ§in mean ve std deÄŸerlerini hesaplÄ±yoruz
def calculate_mean_std(dataset):
    mean = torch.zeros(3)   #RGB
    std = torch.zeros(3)
    total_images = len(dataset)

    for img, _ in dataset:  #resim ve etiktei
        img = transforms.ToTensor()(img)  # GÃ¶rseli tensÃ¶re dÃ¶nÃ¼ÅŸtÃ¼r, 0-255 arasÄ±nda yer alan gÃ¶rsel deÄŸerlerini 0-1 aralÄ±ÄŸÄ±na getirir.
        mean += img.mean(dim=[1, 2])  # (C, H, W) formatÄ±nda: her kanalÄ±n ortalamasÄ±nÄ± al  Ã¶rneÄŸin 5,4 3 kanallÄ± bir resim 3 kanal iÃ§in de tÃ¼m pixeldeki deÄŸerlerin ort ve std si hesaplanÄ±r
        # sonuÃ§  tensor([R_mean, G_mean, B_mean])
        std += img.std(dim=[1, 2])  # Her kanalÄ±n standart sapmasÄ±nÄ± al
        # sonuÃ§  tensor([R_std, G_std, B_std])

    mean /= total_images  # Ortalama deÄŸeri tÃ¼m gÃ¶rseller Ã¼zerinde alÄ±yoruz
    std /= total_images  # Standart sapmayÄ± tÃ¼m gÃ¶rseller Ã¼zerinde alÄ±yoruz

    return mean, std


train_set = torchvision.datasets.ImageFolder(data_dir.joinpath("train"))   #resimlerin bulunduÄŸu klasÃ¶rÃ¼ etiket olarak algÄ±lar etiket ve resim alÄ±r.
mean, std = calculate_mean_std(train_set)

print("EÄŸitim Seti iÃ§in Mean: ", mean)
print("EÄŸitim Seti iÃ§in Std: ", std)


#Ä°LK Ã–NCE EÄÄ°TÄ°M VE VALÄ°DATÄ°ON Ä°Ã‡Ä°N transfor iÅŸlemi
transformTV = transforms.Compose(   #compose iÅŸlemi iÅŸlemlerin sÄ±rayla yapÄ±lmasÄ±nÄ± saÄŸlar
    [
        transforms.Resize((256,256)),
        transforms.RandomVerticalFlip(p=0.25), #yukarÄ±dan aÅŸaÄŸÄ±ya Ã§evirme  oranÄ± kÃ¼Ã§Ã¼k tutacaÄŸÄ±m
        transforms.RandomApply([transforms.RandomRotation(20)], p=0.25), #resmi Ã§evirme biz 10 derece Ã§evirmiÅŸtik her resmi %25 ini de 20 derece Ã§evirsin
        transforms.ToTensor(),  #gÃ¶rÃ¼ntÃ¼lerin PyTorch un tensor formatÄ±na dÃ¶nmesini saÄŸlar.  [3 kanal, en ,boy]
        #3 kanal RGB renkleri oluyor ve bunlarÄ±n ortalamalarÄ± alÄ±nÄ±p normalize ediliyorlar. normalize sonucunda pixellerin z skore deÄŸerleri hesaplanmÄ±ÅŸ oluyor.
        #(H,W,C) (Image tipi) ---> (C,H,W) (Tensor) oluyor.
        transforms.Normalize(mean = mean,std = std)

        #ilk Ã¼Ã§ adÄ±m PIL Ä°mage Ã¼zerinde
        #4.adÄ±m PIL Image pytorch tensorune Ã§evrilir.
        #4. adÄ±m normalized = value - mean/std  deÄŸerler  0-1 arasÄ±na gelir.
    ]
)
#sonra test iÃ§in transform iÅŸlemi
transformT = transforms.Compose(
    [
        transforms.Resize((256,256)),
        transforms.ToTensor(),
        transforms.Normalize(mean = mean,std = std) #test verimiz iÃ§in de aynÄ± Ã§evrimleri yapÄ±yoruz
    ]
)
#ÅŸimdi bu transformlarÄ± verilerimize uygulayalÄ±m
data_dir = pathlib.Path(path)
train_set = torchvision.datasets.ImageFolder(data_dir.joinpath("train"), transform=transformTV)
val_set = torchvision.datasets.ImageFolder(data_dir.joinpath("val"), transform=transformTV)
test_set = torchvision.datasets.ImageFolder(data_dir.joinpath("test"), transform=transformT)

print("\nTransform SonuÃ§larÄ±\n")
print(train_set.transform)
print(val_set.transform)
print(test_set.transform)

################################## TRANSFORMSDAN SONRA VERÄ°LERÄ°MÄ°ZÄ° GÃ–RSELLEÅTÄ°RDÄ°K ###############################

# `brain_label` sÃ¶zlÃ¼ÄŸÃ¼, etiket numarasÄ±na karÅŸÄ±lÄ±k gelen sÄ±nÄ±f adlarÄ±nÄ± saklar
brain_label = {
    0: 'Brain Tumor',
    1: 'Healthy'
}

# Yeni bir figÃ¼r oluÅŸturuyoruz, boyutu 10x10 inch olarak ayarlanÄ±yor
figure = plt.figure(figsize=(10, 10))
cols, rows = 5, 5 #kaÃ§ adet resim olacaÄŸÄ±nÄ± da belirler

for i in range(1, cols * rows + 1):    # `train_set`ten rastgele bir resim ve etiket seÃ§iyoruz
    sample_idx = torch.randint(len(train_set), size=(1,)).item()  # --> 0- train set boyutu kadar bir random deÄŸer seÃ§ilir
    #seÃ§ilen deÄŸerin formatÄ± tensor([5]) ÅŸeklinde gelir . .item() ile bu 5'e Ã§evrilir.
    img, label = train_set[sample_idx]  #label kolasÃ¶rÃ¼n adÄ±nÄ± alÄ±yor yani etiketi

    # Bu gÃ¶rseli figÃ¼rÃ¼n iÃ§ine uygun konuma yerleÅŸtiriyoruz
    ax = figure.add_subplot(rows, cols, i)

    # GÃ¶rselin etiketine gÃ¶re baÅŸlÄ±k rengi belirliyoruz
    # EÄŸer etiket 'Healthy' ise baÅŸlÄ±k yeÅŸil, diÄŸer durumda kÄ±rmÄ±zÄ± olacak
    color = "green" if brain_label[label] == 'Healthy' else "red"

    # BaÅŸlÄ±k ayarlanÄ±yor, font bÃ¼yÃ¼klÃ¼ÄŸÃ¼ 14 ve kalÄ±n yapÄ±lÄ±yor, baÅŸlÄ±k rengi belirleniyor
    ax.set_title(brain_label[label], fontsize=14, fontweight='bold', color=color)

    # GÃ¶rselin eksenlerini gizliyoruz yoksa her resim iÃ§in Ã¶lÃ§ekler Ã§Ä±kÄ±yor
    ax.axis("off")

    # GÃ¶rselin Tensor formatÄ±ndan NumPy formatÄ±na Ã§evriliÅŸi
    img_np = img.numpy().transpose((1, 2, 0))  # (C, H, W) â†’ (H, W, C) formatÄ±na dÃ¶nÃ¼ÅŸÃ¼m PIL
    """(C, H, W) formatÄ±nda bir Tensor'dan,
    (H, W, C) formatÄ±nda bir NumPy array'ine dÃ¶nÃ¼ÅŸÃ¼m yapÄ±lÄ±r."""
    # GÃ¶rselin deÄŸerlerini 0 ile 1 arasÄ±nda kÄ±sÄ±tlÄ±yoruz, bÃ¶ylece gÃ¶rselin doÄŸru ÅŸekilde gÃ¶sterilmesini saÄŸlÄ±yoruz
    img_valid_range = np.clip(img_np, 0, 1)

    # GÃ¶rseli, belirlediÄŸimiz renk aralÄ±ÄŸÄ± ile gÃ¶steriyoruz
    ax.imshow(img_valid_range)

    """
    Tensor'dan NumPy array'e dÃ¶nÃ¼ÅŸÃ¼m: GÃ¶rÃ¼ntÃ¼ verilerini iÅŸlemeye uygun bir formata dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
    BoyutlarÄ±n transpose edilmesi: GÃ¶rselin boyutlarÄ±nÄ±n doÄŸru ÅŸekilde sÄ±ralanmasÄ±nÄ± saÄŸlar, Ã§Ã¼nkÃ¼ gÃ¶rselleÅŸtirme iÅŸlemi iÃ§in matplotlib genellikle (H, W, C) formatÄ±nÄ± bekler.
    np.clip ile 0-1 arasÄ± normalizasyon: GÃ¶rÃ¼ntÃ¼ deÄŸerlerinin doÄŸru aralÄ±kta olmasÄ±nÄ± saÄŸlayarak, gÃ¶rselleÅŸtirme iÃ§in doÄŸru renklerin kullanÄ±lmasÄ±nÄ± saÄŸlar.
    """

# GÃ¶rseller arasÄ±ndaki boÅŸluklarÄ± ayarlÄ±yoruz, hem yatay hem de dikey
plt.subplots_adjust(wspace=0.3, hspace=0.3)
plt.suptitle('Brain Tumor and Healthy Images', fontsize=25, fontweight='bold', y=0.95, color='black')
plt.show()



######################### VERÄ° YUKLEME #############################
batch= 100 #100'ER 100'ER veri alacak

train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch, shuffle=True)
val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_set, batch_size = batch, shuffle = True)

#Bu kÄ±smÄ± her bachte gelen verilerin boyutunu gÃ¶rmek iÃ§in yazdÄ±rdÄ±m.
""" Ã‡Ä±ktÄ±lar aÅŸaÄŸÄ±daki gibi gelecek bunlarÄ±n anlamÄ±;

Shape of X : torch.Size([100, 3, 256, 256])
    bach 100 boyutlu bir resim 
    3 kanallÄ± yani RGB
    256 EN 256 BOY
Shape of y: torch.Size([100]) torch.int64
    100 bach boyutu
    torch.int64 ise etiketli verilerde kullanÄ±lan tensordeki elemanlarÄ±n veri tipidir.
    X RESÄ°M VERÄ°SÄ° , Y Ä°SE Etiketleri """

# Veri yÃ¼kleyicilerdeki eleman sayÄ±larÄ±nÄ± yazdÄ±rmak iÃ§in kod
for key, value in {'Training data': train_loader, "Validation data": val_loader, "Test data": test_loader}.items():
    # Her bir batch'in boyutunu gÃ¶relim
    for X, y in value:
        print(f"{key}:")
        print(f"Shape of X (batch): {X.shape}")
        print(f"Shape of y (batch): {y.shape} {y.dtype}")
        break

    # Toplam eleman sayÄ±sÄ±nÄ± gÃ¶relim
    total_samples = len(value.dataset)
    total_batches = len(value)
    print(f"Total samples in {key}: {total_samples}")   #toplam Ã¶rnek sayÄ±sÄ±
    print(f"Total batches in {key}: {total_batches}")   # batch sayÄ±sÄ±
    print(f"Each batch contains approximately {total_samples / total_batches:.0f} samples")   #her bathcteki Ã¶rnek sayÄ±sÄ± 100 99
    print()

"""
Ã–rnek Ã§Ä±ktÄ± 

Training data:
Shape of X (batch): torch.Size([100, 3, 256, 256])
Shape of y (batch): torch.Size([100]) torch.int64
Total samples in Training data: 9659
Total batches in Training data: 97
Each batch contains approximately 100 samples

"""
######################### CNN MODELÄ° OLUÅTURMA ##############################

import torch.nn as nn  #PyTorchun sinir aÄŸÄ± modelleri yer alÄ±r
import torch.nn.functional as F  #aktivasyon fonksiyonlarÄ± yer alÄ±r.
import torch.optim as optim   #optimizasyon algoritmalarÄ±nÄ± iÃ§erir.
from torch.optim.lr_scheduler import ReduceLROnPlateau   #train loss iyileÅŸmediÄŸinde azalmasÄ±nÄ± saÄŸlar.


torch.backends.cudnn.benchmark = True
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

"""
torch.backends.cudnn.benchmark = True: Bu, CUDA ile Ã§alÄ±ÅŸan sistemlerde, giriÅŸ verisinin boyutlarÄ±na gÃ¶re en uygun algoritmayÄ± seÃ§mek iÃ§in kullanÄ±lÄ±r. Bu, modelin performansÄ±nÄ± artÄ±rabilir.
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'): EÄŸer bir GPU mevcutsa (cuda), model GPU'yu kullanacaktÄ±r. Aksi takdirde, model CPU Ã¼zerinde Ã§alÄ±ÅŸacaktÄ±r.
print(f"Using device: {device}"): Ã‡alÄ±ÅŸma cihazÄ±nÄ±n (CPU veya GPU) hangi cihaz olduÄŸu ekrana yazdÄ±rÄ±lÄ±r.
"""

# KENDÄ° CNN MODELÄ°M
class BrainMRCNN(nn.Module):
    def __init__(self):   #modeli baÅŸlatan fonksiyon
        super(BrainMRCNN, self).__init__()
        # Convolutional Layers
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)  # 3*3 bir maske, padding iÅŸleminde kenarlara 0 eklenir.
        self.bn1 = nn.BatchNorm2d(16)  #Her bir mini-batch iÃ§indeki deÄŸerlerin ortalamasÄ±nÄ± sÄ±fÄ±ra, standart sapmasÄ±nÄ± bire getirir
        """
        : Her konvolÃ¼syon katmanÄ±ndan sonra, Ã¶zellik haritalarÄ±nÄ± normalleÅŸtirerek Ã¶ÄŸrenmeyi hÄ±zlandÄ±rmak iÃ§in kullanÄ±lan bir katmandÄ±r. Bu, modelin daha hÄ±zlÄ± ve stabil Ã¶ÄŸrenmesine yardÄ±mcÄ± olur.
        AktivasyonlarÄ± normalize eder (ortalama 0, standart sapma 1 olacak ÅŸekilde
        """

        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)
        self.bn2 = nn.BatchNorm2d(32)

        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
        self.bn3 = nn.BatchNorm2d(64)

        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)
        self.bn4 = nn.BatchNorm2d(128)

        # Pooling Layer
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)

        # Fully Connected Layers
        self.fc1 = nn.Linear(128 * 16 * 16, 512)
        self.fc2 = nn.Linear(512, 256)
        self.fc3 = nn.Linear(256, 128)  # Yeni eklenen katman
        self.fc4 = nn.Linear(128, 64)   # Yeni eklenen katman
        self.fc5 = nn.Linear(64, 2)     # Ã‡Ä±kÄ±ÅŸ katmanÄ±

        # Dropout Layer
        self.dropout = nn.Dropout(0.2)    # %20 oranÄ±nda nÃ¶ronu overfiti Ã¶nlemek amacÄ±yla devre dÄ±ÅŸÄ± bÄ±rakÄ±r.

    def forward(self, x):
        x = self.pool(F.relu(self.bn1(self.conv1(x))))
        x = self.pool(F.relu(self.bn2(self.conv2(x))))
        x = self.pool(F.relu(self.bn3(self.conv3(x))))
        x = self.pool(F.relu(self.bn4(self.conv4(x))))

        """
         ReLU (Rectified Linear Unit) aktivasyon fonksiyonu uygulanÄ±r. Bu, negatif deÄŸerleri sÄ±fÄ±rlar ve modelin doÄŸrusal olmayan iliÅŸkileri Ã¶ÄŸrenmesini saÄŸlar."""
        # Flatten iÅŸlemi
        x = torch.flatten(x, start_dim=1)  #2 boyut tek boyuta dÃ¼zleÅŸtiriliyor.
        #sÄ±nÄ±flandÄ±rma performansÄ±nÄ± arttÄ±rmak iÃ§in birden fazla Fully connected katman uygulanÄ±r.

        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = F.relu(self.fc2(x))
        x = self.dropout(x)
        x = F.relu(self.fc3(x))  # Yeni eklenen katman
        x = self.dropout(x)
        x = F.relu(self.fc4(x))  # Yeni eklenen katman
        x = self.dropout(x)
        x = self.fc5(x)  # Ã‡Ä±kÄ±ÅŸ katmanÄ± (Aktivasyon uygulanmaz)

        return F.log_softmax(x, dim=1)  #Ã‡Ä±kÄ±ÅŸa softmax fonksiyonu uygulanÄ±r. Bu, her sÄ±nÄ±f iÃ§in olasÄ±lÄ±k deÄŸerini dÃ¶ndÃ¼rÃ¼r.
        # EÄŸer CrossEntropyLoss kullanÄ±yorsan, bunu kaldÄ±rabilirsin. ama NLLLoss KullanÄ±ldÄ±ÄŸÄ± iÃ§in kalacak

    """
Katman	   GiriÅŸ	          Ã‡Ä±kÄ±ÅŸ	            AÃ§Ä±klama
Conv1	(3, 256, 256)	(16, 128, 128)	3â†’16 filtre, pooling ile yarÄ±ya (Maxpooling  2*2 olduÄŸu iÃ§in her iki pixelde bir ilerliyoruz boy yarÄ±ya iniyor)
Conv2	(16, 128, 128)	(32, 64, 64)	16â†’32 filtre
Conv3	(32, 64, 64)	(64, 32, 32)	32â†’64 filtre
Conv4	(64, 32, 32)	(128, 16, 16)	64â†’128 filtre
Flatten	(128, 16, 16) â†’ 32768		Tek boyutlu yapÄ±lÄ±r
FC1 â†’ FC5	32768 â†’ 2		SonuÃ§ta 2 sÄ±nÄ±f Ã§Ä±kÄ±ÅŸÄ± alÄ±nÄ±r

Filtre sayÄ±sÄ± ne kadar fazla olursa o  kadar detay Ã¶ÄŸrenilir. Ã–rneÄŸin 16 filtrenin olmasÄ±
Bir giriÅŸ resmine uygulanacak 16 ayrÄ± filtrenin olacaÄŸÄ±nÄ± sÃ¶yler. Bu da sadece o katmanda 16 
ayrÄ± Ã¶zellik haritasÄ± Ã§Ä±karÄ±lacaÄŸÄ±nÄ± belirtir.

Her konvulasyon katmanÄ±nda bir Ã¶nceki filtreden gelen feature maplerden ortak bir map Ã§Ä±kar.
DiÄŸer konvulasyon katmanÄ± bu map Ã¼zerinde iÅŸlem yapar.

Herbir konum iÃ§in filtre sayÄ±sÄ± kadar patch oluÅŸur (sayÄ± gelir. sayÄ±lar toplanarak o pixelin yeni deÄŸeri oluÅŸturulur)

Fully Con. katmanlarÄ±nda her gelen vektÃ¶r bir aÄŸÄ±rlÄ±k Ã§arpanÄ± ile Ã§arpÄ±larak bias uygulanÄ±r. 
Relu fonksiyonu negatif Ã§Ä±kan deÄŸerleri sÄ±fÄ±rlar.
Bias baÅŸlangÄ±Ã§ noktasÄ±nÄ± kaydÄ±rmaktadÄ±r. Sabit bir deÄŸerdir. Bias da aÄŸÄ±lÄ±klar ile birlikte gÃ¼ncellenir.

    """

# Modeli oluÅŸtur ve parametreleri yazdÄ±r
modelCNN = BrainMRCNN().to(device)
loss_func_cnn = nn.NLLLoss(reduction="sum")
opt_cnn = optim.Adam(modelCNN.parameters(), lr=1e-4)
lr_scheduler_cnn = ReduceLROnPlateau(opt_cnn, mode='min', factor=0.5, patience=20, verbose=1)

"""
2. loss_func_cnn = nn.NLLLoss(reduction="sum")
Bu satÄ±r, kayÄ±p fonksiyonu (loss function) belirler. Burada NLLLoss (Negative Log Likelihood Loss) kullanÄ±lÄ±yor.
nn.NLLLoss: Bu, Ã§ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma problemlerinde kullanÄ±lan bir kayÄ±p fonksiyonudur. Modelin Ã§Ä±ktÄ±larÄ±nÄ±, hedef etiketlerle karÅŸÄ±laÅŸtÄ±rarak kaybÄ± hesaplar. Genelde, log softmax fonksiyonu ile birlikte kullanÄ±lÄ±r.
reduction="sum": Bu parametre, kaybÄ±n nasÄ±l hesaplanacaÄŸÄ±nÄ± belirtir. "sum" deÄŸeri, tÃ¼m Ã¶rnekler iÃ§in kaybÄ±n toplamÄ±nÄ± alÄ±r. Alternatif olarak "mean" seÃ§eneÄŸi, kaybÄ±n ortalamasÄ±nÄ± alÄ±r. "sum" kullanÄ±ldÄ±ÄŸÄ±nda, toplam kaybÄ± elde etmek iÃ§in tÃ¼m mini-batch Ã¼zerindeki kayÄ±plar toplanÄ±r.
Bu kayÄ±p fonksiyonu, modelin tahmin ettiÄŸi log-olasÄ±lÄ±klarla gerÃ§ek etiketler arasÄ±ndaki farkÄ± Ã¶lÃ§er ve bu farkÄ±n toplamÄ±nÄ± geri dÃ¶ndÃ¼rÃ¼r.

3. opt_cnn = optim.Adam(modelCNN.parameters(), lr=1e-4)
Bu satÄ±r, optimizer (optimizatÃ¶r) ayarlarÄ±nÄ± belirler. Burada, Adam optimizatÃ¶rÃ¼ kullanÄ±lÄ±yor.
optim.Adam: Adam (Adaptive Moment Estimation), yaygÄ±n bir optimizasyon algoritmasÄ±dÄ±r. Adam, Ã¶ÄŸrenme oranÄ±nÄ± her parametre iÃ§in ayrÄ± ayrÄ± ayarlar ve daha hÄ±zlÄ± ve etkili bir ÅŸekilde eÄŸitimi saÄŸlar. Adam, Ã¶ÄŸrenme oranÄ± ve momentum gibi parametreleri otomatik olarak gÃ¼nceller.
modelCNN.parameters(): Bu, modeldeki tÃ¼m parametreleri (aÄŸÄ±rlÄ±klar ve biaslar) optimizer'a geÃ§er. Bu sayede optimizer, bu parametreleri gÃ¼ncelleyebilir.
lr=1e-4: Bu, Ã¶ÄŸrenme oranÄ±nÄ± belirtir. Ã–ÄŸrenme oranÄ±, optimizerâ€™Ä±n parametreleri ne kadar hÄ±zlÄ± gÃ¼ncelleyeceÄŸini belirler. 1e-4, yani 0.0001, genellikle iyi bir baÅŸlangÄ±Ã§tÄ±r. 
Ã‡ok bÃ¼yÃ¼k bir Ã¶ÄŸrenme oranÄ± modelin Ã§ok hÄ±zlÄ± Ã¶ÄŸrenmesine neden olabilir, ancak eÄŸitimin stabilitesini bozabilir. KÃ¼Ã§Ã¼k bir Ã¶ÄŸrenme oranÄ± ise daha gÃ¼venli bir eÄŸitim sÃ¼reci saÄŸlar, ancak Ã¶ÄŸrenme sÃ¼reci daha yavaÅŸ olabilir.

4. lr_scheduler_cnn = ReduceLROnPlateau(opt_cnn, mode='min', factor=0.5, patience=20, verbose=1)
Bu satÄ±r, Ã¶ÄŸrenme oranÄ± planlayÄ±cÄ±sÄ± (learning rate scheduler) oluÅŸturur. Burada kullanÄ±lan planlayÄ±cÄ± ReduceLROnPlateau'dir.
ReduceLROnPlateau: Bu scheduler, modelin doÄŸruluÄŸu veya kaybÄ± sabit kaldÄ±ÄŸÄ±nda veya iyileÅŸme durduÄŸunda Ã¶ÄŸrenme oranÄ±nÄ± azaltÄ±r. Bu, modelin eÄŸitim sÃ¼recinde daha verimli bir ÅŸekilde Ã¶ÄŸrenmesini saÄŸlar.
Bu planlayÄ±cÄ±, eÄŸitim sÄ±rasÄ±nda val_loss gibi bir metriÄŸi izler ve eÄŸer belirli bir sayÄ±da epoch boyunca bu metrik iyileÅŸmezse, Ã¶ÄŸrenme oranÄ±nÄ± azaltÄ±r. Bu, modelin daha kÃ¼Ã§Ã¼k Ã¶ÄŸrenme oranlarÄ±yla daha hassas Ã¶ÄŸrenmesine yardÄ±mcÄ± olur.
mode='min': Bu parametre, hangi metriÄŸin izleneceÄŸini belirler. mode='min' olarak ayarlandÄ±ÄŸÄ±nda, val_loss gibi bir kayÄ±p deÄŸeri kÃ¼Ã§Ã¼ldÃ¼kÃ§e Ã¶ÄŸrenme oranÄ± dÃ¼ÅŸer. Yani, kayÄ±p deÄŸeri iyileÅŸmezse Ã¶ÄŸrenme oranÄ± azaltÄ±lÄ±r.
factor=0.5: Bu parametre, Ã¶ÄŸrenme oranÄ±nÄ±n ne kadar azaltÄ±lacaÄŸÄ±nÄ± belirtir. factor=0.5 demek, Ã¶ÄŸrenme oranÄ±nÄ±n her azalmada yarÄ±ya dÃ¼ÅŸeceÄŸi anlamÄ±na gelir.
patience=20: Bu, sabÄ±r parametresidir. EÄŸer belirtilen metrik (Ã¶rneÄŸin kayÄ±p) patience kadar epoch boyunca iyileÅŸmezse, Ã¶ÄŸrenme oranÄ± azaltÄ±lmaya baÅŸlanÄ±r. Yani, patience=20 demek, 20 epoch boyunca kayÄ±p iyileÅŸmezse, Ã¶ÄŸrenme oranÄ± dÃ¼ÅŸÃ¼rÃ¼lÃ¼r.
verbose=1: Bu, sÃ¼reÃ§le ilgili ayrÄ±ntÄ±larÄ±n yazdÄ±rÄ±lmasÄ±nÄ± saÄŸlar. verbose=1 olduÄŸunda, Ã¶ÄŸrenme oranÄ±nÄ±n azalmasÄ± hakkÄ±nda bilgi yazdÄ±rÄ±lÄ±r.
"""
#--------------------------------------------------------------------------------------

# MODEL: DENSENET169
"""
DenseNet'in en Ã¶nemli Ã¶zelliÄŸi, her katmanÄ±n kendisinden Ã¶nceki tÃ¼m katmanlardan giriÅŸ almasÄ±dÄ±r. 
EÄŸer L katmanlÄ± bir aÄŸ varsa, geleneksel CNN'de L baÄŸlantÄ± vardÄ±r, ancak DenseNet'te L(L+1)/2 baÄŸlantÄ± bulunur. 
Bu, bilginin daha iyi akmasÄ±nÄ± ve gradyanlarÄ±n daha iyi yayÄ±lmasÄ±nÄ± saÄŸlar.

Geleneksel CNN: xâ‚€ â†’ Hâ‚ â†’ Hâ‚‚ â†’ ... â†’ Ã‡Ä±ktÄ±
DenseNet: xâ‚€ â†’ Hâ‚ â†’ Hâ‚‚(xâ‚€,Hâ‚) â†’ Hâ‚ƒ(xâ‚€,Hâ‚,Hâ‚‚) â†’ ... â†’ Ã‡Ä±ktÄ±

DenseNet169: Ã–nceden eÄŸitilmiÅŸ (pretrained) bir model kullanÄ±yor. ImageNet veri seti Ã¼zerinde milyonlarca gÃ¶rÃ¼ntÃ¼yle eÄŸitilmiÅŸ derin bir mimari.
"""


from torchvision import models

# Pretrained DenseNet169 modelini yÃ¼kle
modelDense = models.densenet169(pretrained=True)

# TÃ¼m katmanlarÄ± dondur (sadece yeni eklenen classifier eÄŸitilecek)
for param in modelDense.parameters():
    param.requires_grad = False
"""
Bu kod, mevcut tÃ¼m katmanlarÄ± "donduruyor" - yani bu katmanlarÄ±n aÄŸÄ±rlÄ±klarÄ± eÄŸitim sÄ±rasÄ±nda gÃ¼ncellenmeyecek.

DenseNet169, farklÄ± bir gÃ¶rev (genel nesne tanÄ±ma) iÃ§in eÄŸitilmiÅŸ olsa da, ilk katmanlarÄ± kenarlar, dokular ve ÅŸekiller gibi temel gÃ¶rsel Ã¶zellikleri tanÄ±mayÄ± Ã¶ÄŸrenmiÅŸtir.
Bu temel Ã¶zellikler, beyin MR gÃ¶rÃ¼ntÃ¼lerindeki yapÄ±larÄ± tanÄ±mak iÃ§in de yararlÄ±dÄ±r.
Dondurma iÅŸlemi ile, temel Ã¶zellikleri tanÄ±ma yeteneÄŸini korurken, sadece son katmanlarÄ± (sÄ±nÄ±flandÄ±rÄ±cÄ±) yeni gÃ¶rev iÃ§in Ã¶zelleÅŸtiriyorsunuz.

Bu yaklaÅŸÄ±m, Ã¶zellikle veri setiniz kÃ¼Ã§Ã¼kse (birkaÃ§ yÃ¼z veya birkaÃ§ bin gÃ¶rÃ¼ntÃ¼), sÄ±fÄ±rdan eÄŸitilen bir modele gÃ¶re genellikle daha iyi sonuÃ§lar verir ve eÄŸitim sÃ¼resi Ã§ok daha kÄ±sadÄ±r.
"""
# Son katmanÄ± (classifier) deÄŸiÅŸtir
num_ftrs = modelDense.classifier.in_features
modelDense.classifier = nn.Sequential(
    nn.Linear(num_ftrs, 512),
    nn.ReLU(),
    nn.Dropout(0.2),
    nn.Linear(512, 256),
    nn.ReLU(),
    nn.Dropout(0.2),
    nn.Linear(256, 128),
    nn.ReLU(),
    nn.Dropout(0.2),
    nn.Linear(128, 64),
    nn.ReLU(),
    nn.Dropout(0.2),
    nn.Linear(64, 2),  # Ã‡Ä±kÄ±ÅŸ katmanÄ±
    nn.LogSoftmax(dim=1)
)

# Modeli cihaza gÃ¶nder
modelDense = modelDense.to(device)
# KayÄ±p fonksiyonu ve optimizer
loss_func_dense = nn.NLLLoss(reduction="sum")  # EÄŸer CrossEntropyLoss kullanÄ±yorsan LogSoftmax'Ä± kaldÄ±r
opt_dense = optim.Adam(modelDense.classifier.parameters(), lr=1e-4)  # Sadece classifier eÄŸitilecek
lr_scheduler_dense = ReduceLROnPlateau(opt_dense, mode='min', factor=0.5, patience=20, verbose=1)
#--------------------------------------------------------------------------------------

# MODEL: Inception-ResNetV2
"""
Inception-ResNetV2: Ä°ki gÃ¼Ã§lÃ¼ mimariyi birleÅŸtirir - Inception ve ResNet.
Inception modÃ¼lleri (paralel farklÄ± boyutlardaki filtreler) ve ResNet'in artÄ±k baÄŸlantÄ±larÄ±nÄ± (residual connections) bir arada kullanÄ±r.

Google'Ä±n geliÅŸtirdiÄŸi Ã§ok derin (572 katman) ve karmaÅŸÄ±k bir mimaridir. 55.8 milyon parametre iÃ§erir.
En yÃ¼ksek hesaplama ve bellek gereksinimine sahiptir.
Inception-ResNetV2'nin belirleyici Ã¶zelliklerinden biri, paralel farklÄ± boyutlarda filtreler (1x1, 3x3, 5x5) kullanmasÄ±dÄ±r. 
Bu, farklÄ± Ã¶lÃ§eklerdeki Ã¶zellikleri aynÄ± anda yakalayabilme yeteneÄŸi saÄŸlar.
"""

import pretrainedmodels
import torch
import torch.nn as nn

# Inception-ResNet-V2 modelini yÃ¼kle
modelResnet = pretrainedmodels.__dict__['inceptionresnetv2'](pretrained='imagenet')
"""
 (pretrainedmodels) kullanÄ±lÄ±yor. Bu kÃ¼tÃ¼phane, PyTorch'ta resmi olarak bulunmayan bazÄ± modern mimarilere eriÅŸim saÄŸlar.
"""
# TÃ¼m katmanlarÄ± dondur (sadece son sÄ±nÄ±flandÄ±rÄ±cÄ±yÄ± eÄŸiteceÄŸiz)
for param in modelResnet.parameters():
    param.requires_grad = False

# Modelin son katmanÄ±nÄ± deÄŸiÅŸtiriyoruz
num_ftrs = modelResnet.last_linear.in_features  # Son katmandaki input boyutunu alÄ±yoruz

# Adaptive Pooling ekleyerek hatayÄ± dÃ¼zelt
modelResnet.avgpool_1a = nn.AdaptiveAvgPool2d((1, 1))

# Son katmanÄ± deÄŸiÅŸtir
modelResnet.last_linear = nn.Sequential(
    nn.Linear(num_ftrs, 512),
    nn.ReLU(),
    nn.Dropout(0.2),
    nn.Linear(512, 256),
    nn.ReLU(),
    nn.Dropout(0.2),
    nn.Linear(256, 128),
    nn.ReLU(),
    nn.Dropout(0.2),
    nn.Linear(128, 64),
    nn.ReLU(),
    nn.Dropout(0.2),
    nn.Linear(64, 2),
    nn.LogSoftmax(dim=1)
)

modelResnet = modelResnet.to(device)
# Loss function ve optimizer
loss_func_resnet = nn.NLLLoss(reduction="sum")  # NLLLoss kullandÄ±k, Ã§Ã¼nkÃ¼ LogSoftmax kullanÄ±yoruz
opt_resnet = torch.optim.Adam(modelResnet.parameters(), lr=1e-4)
lr_scheduler_resnet = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_resnet, mode='min', factor=0.5, patience=20,
                                                                 verbose=1)

"""
Inception-ResNetV2 Tercih EdildiÄŸinde:

En yÃ¼ksek doÄŸruluk gerektiren kritik uygulamalarda
Yeterli hesaplama gÃ¼cÃ¼ ve bellek mevcutsa
Veri seti yeterince bÃ¼yÃ¼kse veya gÃ¼Ã§lÃ¼ veri artÄ±rma (data augmentation) kullanÄ±lÄ±yorsa
FarklÄ± Ã¶lÃ§eklerdeki Ã¶zellikleri tanÄ±manÄ±n Ã¶nemli olduÄŸu durumlarda (Ã¶rn. Ã§ok kÃ¼Ã§Ã¼k tÃ¼mÃ¶rler ve geniÅŸ beyin yapÄ±larÄ± bir arada)

DenseNet169 Tercih EdildiÄŸinde:

Orta dÃ¼zeyde hesaplama kaynaklarÄ± varsa
Ä°yi bir doÄŸruluk/hesaplama oranÄ± gerektiÄŸinde
Veri seti kÃ¼Ã§Ã¼k-orta boyutluysa
Ã–zellik yeniden kullanÄ±mÄ±nÄ±n Ã¶nemli olduÄŸu durumlarda

Ã–zel CNN Tercih EdildiÄŸinde:

SÄ±nÄ±rlÄ± hesaplama kaynaklarÄ±nda
Ã‡ok kÃ¼Ã§Ã¼k veri setlerinde
HÄ±zlÄ± eÄŸitim ve Ã§Ä±karÄ±m (inference) gerektiÄŸinde
Problem basitse ve karmaÅŸÄ±k Ã¶zellik Ã§Ä±karÄ±mÄ± gerektirmiyorsa
"""

# --------------------------------------------------------------------------------------

from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, \
    classification_report


def calculate_metrics(y_true, y_pred):
    """
    Performans metriklerini hesaplayan yardÄ±mcÄ± fonksiyon
    """
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, average='weighted')  # hasta tahmin ettiklerinden kaÃ§Ä± gerÃ§ekte hasta
    recall = recall_score(y_true, y_pred, average='weighted')  # gerÃ§ekte hasta olanlarÄ±n kaÃ§Ä±nÄ± doÄŸru bildi
    f1 = f1_score(y_true, y_pred, average='weighted')

    return accuracy, precision, recall, f1


def train_epoch(model, train_loader, loss_func, optimizer, device):
    model.train()
    total_loss = 0
    predictions = []
    true_labels = []

    # For loop baÅŸlamadan Ã¶nce, kaÃ§ batch olduÄŸunu yazdÄ±r
    total_batches = len(train_loader)
    print(f"Training on {len(train_loader.dataset)} samples with {total_batches} batches")

    for batch_idx, (data, target) in enumerate(train_loader):
        # Ä°lerleme bilgisini yazdÄ±r
        print(f"Processing batch {batch_idx + 1}/{total_batches} ({(batch_idx + 1) * 100 / total_batches:.1f}%)")

        # Veriyi GPU'ya taÅŸÄ±
        data, target = data.to(device), target.to(device)

        optimizer.zero_grad()  # Her adÄ±mda Ã¶nceki gradyanlarÄ± sÄ±fÄ±rlamak gerekir    GradyanÄ± kullanarak â€œhangi aÄŸÄ±rlÄ±ÄŸÄ± ne kadar deÄŸiÅŸtirmeliyim ki hata azalsÄ±nâ€ sorusuna cevap veririz.
        output = model(data)  # Modelin tahmini (log_softmax Ã§Ä±ktÄ±sÄ±).
        loss = loss_func(output, target)  # NLLLoss, tahmin ile gerÃ§ek deÄŸer arasÄ±ndaki kaybÄ± hesaplar.

        loss.backward()  # GradyanlarÄ± hesaplar.
        optimizer.step()  # Bu gradyanlara gÃ¶re modelin aÄŸÄ±rlÄ±klarÄ±nÄ± gÃ¼nceller.

        total_loss += loss.item()  # Her batchâ€™teki loss, toplam lossâ€™a eklenir.

        pred = output.argmax(dim=1, keepdim=True)  # Hangi sÄ±nÄ±fa ait olduÄŸunu bulur (Ã¶rneÄŸin [0.2, 0.8] â†’ sÄ±nÄ±f 1).
        # CPU'ya taÅŸÄ±yÄ±p numpy'a Ã§evir
        predictions.extend(
            pred.cpu().detach().numpy().flatten())  # NumPyâ€™ya Ã§evirerek gradyan takibinden Ã§Ä±karÄ±lÄ±r ve CPUâ€™ya alÄ±nÄ±r.
        true_labels.extend(target.cpu().numpy().flatten())

    accuracy, precision, recall, f1 = calculate_metrics(true_labels, predictions)
    avg_loss = total_loss / len(train_loader.dataset)

    return avg_loss, accuracy, precision, recall, f1


def validate(model, val_loader, loss_func,
             device):  # validation eÄŸitmez sadece ne kadar eÄŸitildiÄŸini test eder. aÄŸÄ±rlÄ±klar gÃ¼ncellenmez, gradyan hesaplanmaz
    model.eval()
    total_loss = 0
    predictions = []
    true_labels = []

    with torch.no_grad():
        for data, target in val_loader:
            # Veriyi GPU'ya taÅŸÄ±
            data, target = data.to(device), target.to(device)

            output = model(data)
            loss = loss_func(output, target)
            total_loss += loss.item()

            pred = output.argmax(dim=1, keepdim=True)
            # CPU'ya taÅŸÄ±yÄ±p numpy'a Ã§evir
            predictions.extend(pred.cpu().numpy().flatten())
            true_labels.extend(target.cpu().numpy().flatten())

    accuracy, precision, recall, f1 = calculate_metrics(true_labels, predictions)
    avg_loss = total_loss / len(val_loader.dataset)

    return avg_loss, accuracy, precision, recall, f1


def early_stopping(history, patience=3):
    val_losses = history['val_losses']

    if len(val_losses) < patience + 1:
        return len(val_losses)

    # Son 'patience' sayÄ±sÄ± kadar epochta kayÄ±p dÃ¼ÅŸmediyse durdur
    for i in range(len(val_losses) - patience, len(val_losses)):
        if val_losses[i] < val_losses[i - 1]:
            return len(val_losses)

    # Erken durdurma gerekli
    print(f"\nğŸ’¡ Erken Durdurma: Son {patience} epochta kayÄ±p dÃ¼ÅŸmedi!")
    return len(val_losses) - patience


def train_model(model, model_name, train_loader, val_loader, loss_func, optimizer, lr_scheduler, device,
                num_epochs=100):
    """
    Modeli eÄŸiten ana fonksiyon
    """
    print(f"\n{'=' * 20} {model_name} MODELI EÄITILIYOR {'=' * 20}")

    # Metrik geÃ§miÅŸini tutmak iÃ§in listeler
    train_losses = []
    train_accuracies = []
    val_losses = []
    val_accuracies = []

    best_val_loss = float('inf')  # Ä°lk baÅŸta Ã§ok bÃ¼yÃ¼k bir deÄŸer ata
    model_filename = f"{model_name}.pth"  # Model dosya adÄ±

    for epoch in range(num_epochs):
        train_loss, train_acc, train_prec, train_recall, train_f1 = train_epoch(
            model, train_loader, loss_func, optimizer, device
        )
        val_loss, val_acc, val_prec, val_recall, val_f1 = validate(
            model, val_loader, loss_func, device
        )

        # En iyi modeli kaydetme
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save(model.state_dict(), model_filename)
            print(f"Epoch {epoch + 1}: Best model saved with validation loss {val_loss:.4f}")

        # Learning rate scheduler'Ä± gÃ¼ncelle
        lr_scheduler.step(val_loss)

        # Metrikleri kaydet
        train_losses.append(train_loss)
        train_accuracies.append(train_acc)
        val_losses.append(val_loss)
        val_accuracies.append(val_acc)

        # SonuÃ§larÄ± yazdÄ±r
        print(f'Epoch {epoch + 1}/{num_epochs}')
        print(
            f'Training - Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}, Precision: {train_prec:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}')
        print(
            f'Validation - Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}, Precision: {val_prec:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}\n')

        # Early stopping kontrolÃ¼
        if epoch >= 3:  # En az 3 epoch sonra kontrol et
            stop_epoch = early_stopping({
                'train_losses': train_losses,
                'val_losses': val_losses
            }, patience=3)

            if stop_epoch != len(train_losses):
                print(f"\n EÄŸitim {stop_epoch}. epochta erken durduruldu!")
                break

    print(f"\n{'=' * 20} {model_name} MODELI EÄITIMI TAMAMLANDI {'=' * 20}\n")

    return {
        'train_losses': train_losses,
        'train_accuracies': train_accuracies,
        'val_losses': val_losses,
        'val_accuracies': val_accuracies
    }


def plot_metrics(history, model_name):
    """
    EÄŸitim ve validation metriklerini Ã§izdiren fonksiyon
    """
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

    # BaÅŸlÄ±k ekleyelim
    fig.suptitle(f"{model_name} - EÄŸitim Metrikleri", fontsize=16)

    # Loss grafiÄŸi
    ax1.plot(history['train_losses'], label='Training Loss')
    ax1.plot(history['val_losses'], label='Validation Loss')
    ax1.set_title('Loss over epochs')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.legend()  # Ã§Ä±ktÄ±da saÄŸ Ã¼stteki gÃ¶sterim

    # Accuracy grafiÄŸi
    ax2.plot(history['train_accuracies'], label='Training Accuracy')
    ax2.plot(history['val_accuracies'], label='Validation Accuracy')
    ax2.set_title('Accuracy over epochs')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Accuracy')
    ax2.legend()

    plt.tight_layout()
    plt.show()


def test_model(model, model_name, test_loader, device):
    # Modeli yÃ¼kle
    model_filename = f"{model_name}.pth"
    model.load_state_dict(torch.load(model_filename, map_location=device, weights_only=True))  # modeli yÃ¼klÃ¼yoruz
    model.eval()

    print(f"\n{'=' * 20} {model_name} MODELI TEST EDILIYOR {'=' * 20}")

    # Loss fonksiyonunu tanÄ±mla
    criterion = torch.nn.NLLLoss()

    # Test iÃ§in hazÄ±rlÄ±k
    all_preds = []
    all_labels = []
    total_loss = 0.0  # Test loss hesaplamak iÃ§in deÄŸiÅŸken

    with torch.no_grad():  # geriye yayÄ±lÄ±m ve gradyan hesaplama kapatÄ±lÄ±r.
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)

            # Model tahmini yap
            output = model(data)

            # Loss'u hesapla
            loss = criterion(output, target)
            total_loss += loss.item()  # Batch loss'unu topla

            # Tahminleri al
            pred = output.argmax(dim=1, keepdim=True)
            all_preds.extend(pred.cpu().numpy().flatten())
            all_labels.extend(target.cpu().numpy().flatten())

    # Ortalama test loss'u hesapla
    average_test_loss = total_loss / len(test_loader)
    print(f'\nTest Loss: {average_test_loss:.4f}')

    # Confusion Matrix hesapla
    cm = confusion_matrix(all_labels, all_preds)

    # SÄ±nÄ±f isimleri
    class_names = ['Brain Tumor', 'Healthy']

    # Performans raporu
    print("\nDetaylÄ± Performans Raporu:")
    print(classification_report(all_labels, all_preds, target_names=class_names))

    # Confusion Matrix gÃ¶rselleÅŸtirme
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
    plt.title(f'{model_name} - Confusion Matrix')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.tight_layout()
    plt.show()

    print(f"\n{'=' * 20} {model_name} MODELI TEST TAMAMLANDI {'=' * 20}\n")

    return cm, average_test_loss


def test_single_image(model, model_name, image_path, mean, std, device):
    print(f"\n{model_name} modeli ile gÃ¶rÃ¼ntÃ¼ test ediliyor: {os.path.basename(image_path)}")

    # Modeli yÃ¼kle
    model_filename = f"{model_name}.pth"
    model.load_state_dict(torch.load(model_filename, map_location=device))

    # Ã–n iÅŸleme iÃ§in dÃ¶nÃ¼ÅŸÃ¼mleri tanÄ±mla
    transformT = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
        transforms.Normalize(mean=mean, std=std)  # Test verisi iÃ§in de aynÄ± iÅŸlemler
    ])

    # GÃ¶rÃ¼ntÃ¼yÃ¼ aÃ§ ve dÃ¶nÃ¼ÅŸtÃ¼r
    image = Image.open(image_path).convert("RGB")
    image = transformT(image).unsqueeze(0).to(device)  # Batch boyutu ekleyerek modele uygun hale getir

    # Modeli deÄŸerlendir moduna al
    model.eval()
    with torch.no_grad():
        output = model(image)
        prediction = output.argmax(dim=1).item()  # En yÃ¼ksek olasÄ±lÄ±ÄŸa sahip sÄ±nÄ±fÄ± al

    # Etiketleri sÃ¶zlÃ¼k ile eÅŸleÅŸtir
    label_dict = {0: "ğŸ§  Brain Tumor", 1: "âœ… Healthy"}
    print(f"{model_name} Tahmini: {label_dict[prediction]}")


# Ana eÄŸitim ve test dÃ¶ngÃ¼sÃ¼
def train_and_evaluate_models(models_dict, train_loader, val_loader, test_loader, device, mean, std, num_epochs=15):
    """
    Birden fazla modeli sÄ±rayla eÄŸitip test eden fonksiyon

    Args:
        models_dict: {model_name: (model, loss_func, optimizer, scheduler)} ÅŸeklinde sÃ¶zlÃ¼k
        train_loader: EÄŸitim veri yÃ¼kleyicisi
        val_loader: DoÄŸrulama veri yÃ¼kleyicisi
        test_loader: Test veri yÃ¼kleyicisi
        device: EÄŸitim cihazÄ± (cuda/cpu)
        mean: Normalizasyon iÃ§in ortalama deÄŸerler
        std: Normalizasyon iÃ§in standart sapma deÄŸerleri
        num_epochs: Maksimum epoch sayÄ±sÄ±
    """
    model_results = {}  # sonuÃ§lar buraya gelecek

    # Her modeli sÄ±rayla eÄŸit ve test et
    for model_name, (
    model, loss_func, optimizer, scheduler) in models_dict.items():  # items key value deÄŸerini tupple ÅŸeklinde dÃ¶ndÃ¼rÃ¼r
        # EÄŸer model dosyasÄ± yoksa, modeli eÄŸit
        if not os.path.exists(f"{model_name}.pth"):
            history = train_model(
                model=model,
                model_name=model_name,
                train_loader=train_loader,
                val_loader=val_loader,
                loss_func=loss_func,
                optimizer=optimizer,
                lr_scheduler=scheduler,
                device=device,
                num_epochs=num_epochs
            )

            # EÄŸitim metriklerini Ã§izdir
            plot_metrics(history, model_name)

        # Modeli test et
        cm, avg_test_loss = test_model(model, model_name, test_loader, device)
        model_results[model_name] = {'confusion_matrix': cm, 'test_loss': avg_test_loss}

    # TÃ¼m modelleri karÅŸÄ±laÅŸtÄ±r
    print("\n" + "=" * 60)
    print("MODELLERIN KARÅILAÅTIRMASI")
    print("=" * 60)

    for model_name, results in model_results.items():
        print(f"{model_name} - Test Loss: {results['test_loss']:.4f}")

    print("=" * 60)

    # Test gÃ¶rÃ¼ntÃ¼leri Ã¼zerinde her modeli dene
    test_images = [
        r"...new output folder path...\brain\test\Brain Tumor\flip_Cancer (1841).jpg",
        r"...new output folder path...\brain\test\Brain Tumor\flip_Cancer (1745).jpg",
        r"...new output folder path...\brain\test\Brain Tumor\original_Cancer (819).jpg",
        r"...new output folder path...\brain\test\Healthy\flip_Not Cancer  (118).jpg"
    ]

    for image_path in test_images:
        print("\n" + "-" * 60)
        print(f"Test Image: {os.path.basename(image_path)}")  # yolun son ksÄ±mÄ±ndan resmin sedece ismi alÄ±nÄ±yor
        print("-" * 60)

        for model_name, (model, _, _, _) in models_dict.items():
            test_single_image(model, model_name, image_path, mean, std, device)


# Modelleri bir sÃ¶zlÃ¼kte toplayÄ±n
models_dict = {
    'modelCNN': (modelCNN, loss_func_cnn, opt_cnn, lr_scheduler_cnn),
    'modelDense': (modelDense, loss_func_dense, opt_dense, lr_scheduler_dense),
    'modelResnet': (modelResnet, loss_func_resnet, opt_resnet, lr_scheduler_resnet)
}

# TÃ¼m modelleri eÄŸit ve test et
train_and_evaluate_models(
    models_dict,
    train_loader,
    val_loader,
    test_loader,
    device,
    mean,  # Normalizasyon iÃ§in mean deÄŸeri
    std,  # Normalizasyon iÃ§in std deÄŸeri
    num_epochs=15
)